[2024-12-05T20:58:27.957+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-12-05T20:58:27.968+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: brand_category_mapping.extract_sql manual__2024-12-05T20:58:00.757576+00:00 [queued]>
[2024-12-05T20:58:27.973+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: brand_category_mapping.extract_sql manual__2024-12-05T20:58:00.757576+00:00 [queued]>
[2024-12-05T20:58:27.974+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 4
[2024-12-05T20:58:27.985+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): extract_sql> on 2024-12-05 20:58:00.757576+00:00
[2024-12-05T20:58:27.990+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=2663) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-12-05T20:58:27.991+0000] {standard_task_runner.py:72} INFO - Started process 2671 to run task
[2024-12-05T20:58:27.992+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'brand_category_mapping', 'extract_sql', 'manual__2024-12-05T20:58:00.757576+00:00', '--job-id', '589', '--raw', '--subdir', 'DAGS_FOLDER/llm_mapping.py', '--cfg-path', '/tmp/tmplcutq7wy']
[2024-12-05T20:58:27.994+0000] {standard_task_runner.py:105} INFO - Job 589: Subtask extract_sql
[2024-12-05T20:58:28.026+0000] {task_command.py:467} INFO - Running <TaskInstance: brand_category_mapping.extract_sql manual__2024-12-05T20:58:00.757576+00:00 [running]> on host c7780884450d
[2024-12-05T20:58:28.085+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='artzsh' AIRFLOW_CTX_DAG_ID='brand_category_mapping' AIRFLOW_CTX_TASK_ID='extract_sql' AIRFLOW_CTX_EXECUTION_DATE='2024-12-05T20:58:00.757576+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-05T20:58:00.757576+00:00'
[2024-12-05T20:58:28.086+0000] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-05T20:58:28.103+0000] {llm_mapping.py:187} INFO - Извлечён llm_response: Here are the categories assigned to each brand based on the search results and context:

1. **alphard** - electronics
2. **alpicool** - appliances
3. **alpika** - apparel
4. **alpina** - apparel
5. **alpinapabliser** - apparel
6. **alpine** - electronics, auto
7. **alser** - electronics
8. **altacto** - electronics
9. **altair** - electronics
10. **alteco** - construction
11. **altel** - electronics
12. **alterna** - electronics
13. **alternativa** - apparel
14. **altex** - electronics
15. **altinbasak** - apparel
16. **altrad** - construction
17. **alumet** - construction
18. **alutec** - construction
19. **alvarez** - furniture
20. **alveus** - appliances
21. **alvitek** - electronics
22. **alvo** - electronics
23. **alza** - electronics
24. **amalbooks** - stationery
25. **amarobaby** - kids, apparel

Now, here is the SQL INSERT statement:

```sql
INSERT INTO "DDS".brand_category_mapping (brand, category_index) VALUES
    ('alphard', 'electronics'),
    ('alpicool', 'appliances'),
    ('alpika', 'apparel'),
    ('alpina', 'apparel'),
    ('alpinapabliser', 'apparel'),
    ('alpine', 'electronics'),
    ('alpine', 'auto'),
    ('alser', 'electronics'),
    ('altacto', 'electronics'),
    ('altair', 'electronics'),
    ('alteco', 'construction'),
    ('altel', 'electronics'),
    ('alterna', 'electronics'),
    ('alternativa', 'apparel'),
    ('altex', 'electronics'),
    ('altinbasak', 'apparel'),
    ('altrad', 'construction'),
    ('alumet', 'construction'),
    ('alutec', 'construction'),
    ('alvarez', 'furniture'),
    ('alveus', 'appliances'),
    ('alvitek', 'electronics'),
    ('alvo', 'electronics'),
    ('alza', 'electronics'),
    ('amalbooks', 'stationery'),
    ('amarobaby', 'kids'),
    ('amarobaby', 'apparel');
```
[2024-12-05T20:58:28.103+0000] {llm_mapping.py:174} INFO - Извлечён SQL-код:
INSERT INTO "DDS".brand_category_mapping (brand, category_index) VALUES
    ('alphard', 'electronics'),
    ('alpicool', 'appliances'),
    ('alpika', 'apparel'),
    ('alpina', 'apparel'),
    ('alpinapabliser', 'apparel'),
    ('alpine', 'electronics'),
    ('alpine', 'auto'),
    ('alser', 'electronics'),
    ('altacto', 'electronics'),
    ('altair', 'electronics'),
    ('alteco', 'construction'),
    ('altel', 'electronics'),
    ('alterna', 'electronics'),
    ('alternativa', 'apparel'),
    ('altex', 'electronics'),
    ('altinbasak', 'apparel'),
    ('altrad', 'construction'),
    ('alumet', 'construction'),
    ('alutec', 'construction'),
    ('alvarez', 'furniture'),
    ('alveus', 'appliances'),
    ('alvitek', 'electronics'),
    ('alvo', 'electronics'),
    ('alza', 'electronics'),
    ('amalbooks', 'stationery'),
    ('amarobaby', 'kids'),
    ('amarobaby', 'apparel');
[2024-12-05T20:58:28.104+0000] {python.py:240} INFO - Done. Returned value was: INSERT INTO "DDS".brand_category_mapping (brand, category_index) VALUES
    ('alphard', 'electronics'),
    ('alpicool', 'appliances'),
    ('alpika', 'apparel'),
    ('alpina', 'apparel'),
    ('alpinapabliser', 'apparel'),
    ('alpine', 'electronics'),
    ('alpine', 'auto'),
    ('alser', 'electronics'),
    ('altacto', 'electronics'),
    ('altair', 'electronics'),
    ('alteco', 'construction'),
    ('altel', 'electronics'),
    ('alterna', 'electronics'),
    ('alternativa', 'apparel'),
    ('altex', 'electronics'),
    ('altinbasak', 'apparel'),
    ('altrad', 'construction'),
    ('alumet', 'construction'),
    ('alutec', 'construction'),
    ('alvarez', 'furniture'),
    ('alveus', 'appliances'),
    ('alvitek', 'electronics'),
    ('alvo', 'electronics'),
    ('alza', 'electronics'),
    ('amalbooks', 'stationery'),
    ('amarobaby', 'kids'),
    ('amarobaby', 'apparel');
[2024-12-05T20:58:28.119+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-05T20:58:28.119+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=brand_category_mapping, task_id=extract_sql, run_id=manual__2024-12-05T20:58:00.757576+00:00, execution_date=20241205T205800, start_date=20241205T205827, end_date=20241205T205828
[2024-12-05T20:58:28.165+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2024-12-05T20:58:28.184+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-12-05T20:58:28.187+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
