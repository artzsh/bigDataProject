[2024-12-05T21:05:41.706+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-12-05T21:05:41.720+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: brand_category_mapping.extract_sql manual__2024-12-05T21:05:16.656190+00:00 [queued]>
[2024-12-05T21:05:41.727+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: brand_category_mapping.extract_sql manual__2024-12-05T21:05:16.656190+00:00 [queued]>
[2024-12-05T21:05:41.727+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 4
[2024-12-05T21:05:41.741+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): extract_sql> on 2024-12-05 21:05:16.656190+00:00
[2024-12-05T21:05:41.749+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=3056) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-12-05T21:05:41.750+0000] {standard_task_runner.py:72} INFO - Started process 3057 to run task
[2024-12-05T21:05:41.751+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'brand_category_mapping', 'extract_sql', 'manual__2024-12-05T21:05:16.656190+00:00', '--job-id', '673', '--raw', '--subdir', 'DAGS_FOLDER/llm_mapping.py', '--cfg-path', '/tmp/tmph99xl0dx']
[2024-12-05T21:05:41.753+0000] {standard_task_runner.py:105} INFO - Job 673: Subtask extract_sql
[2024-12-05T21:05:41.790+0000] {task_command.py:467} INFO - Running <TaskInstance: brand_category_mapping.extract_sql manual__2024-12-05T21:05:16.656190+00:00 [running]> on host c7780884450d
[2024-12-05T21:05:41.859+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='artzsh' AIRFLOW_CTX_DAG_ID='brand_category_mapping' AIRFLOW_CTX_TASK_ID='extract_sql' AIRFLOW_CTX_EXECUTION_DATE='2024-12-05T21:05:16.656190+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-05T21:05:16.656190+00:00'
[2024-12-05T21:05:41.860+0000] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-05T21:05:41.879+0000] {llm_mapping.py:187} INFO - Извлечён llm_response: Here is the mapping of the brands to their respective categories based on the search queries:

1. **baraka**: medicine
2. **baratto**: furniture
3. **barbie**: kids, apparel
4. **barcelona**: apparel
5. **bardahl**: auto, appliances
6. **barer**: electronics
7. **barettoni**: apparel
8. **barhatnyjsezon**: apparel
9. **barkan**: electronics
10. **barmila**: appliances
11. **barneo**: appliances
12. **barokko**: furniture
13. **baron**: furniture
14. **baroque**: furniture
15. **barretoni**: apparel
16. **bars**: appliances
17. **bartek**: kids, apparel
18. **bartplast**: construction
19. **barty**: stationery
20. **basaran**: construction
21. **baseus**: electronics
22. **basf**: construction
23. **basharan**: electronics
24. **b.a.shop**: apparel
25. **basic**: apparel

Now, here is the SQL INSERT statement based on the assigned categories:

```sql
INSERT INTO "DDS".brand_category_mapping (brand, category_index) VALUES
    ('baraka', 'medicine'),
    ('baratto', 'furniture'),
    ('barbie', 'kids'),
    ('barbie', 'apparel'),
    ('barcelona', 'apparel'),
    ('bardahl', 'auto'),
    ('bardahl', 'appliances'),
    ('barer', 'electronics'),
    ('barettoni', 'apparel'),
    ('barhatnyjsezon', 'apparel'),
    ('barkan', 'electronics'),
    ('barmila', 'appliances'),
    ('barneo', 'appliances'),
    ('barokko', 'furniture'),
    ('baron', 'furniture'),
    ('baroque', 'furniture'),
    ('barretoni', 'apparel'),
    ('bars', 'appliances'),
    ('bartek', 'kids'),
    ('bartek', 'apparel'),
    ('bartplast', 'construction'),
    ('barty', 'stationery'),
    ('basaran', 'construction'),
    ('baseus', 'electronics'),
    ('basf', 'construction'),
    ('basharan', 'electronics'),
    ('b.a.shop', 'apparel'),
    ('basic', 'apparel');
```
[2024-12-05T21:05:41.880+0000] {llm_mapping.py:174} INFO - Извлечён SQL-код:
INSERT INTO "DDS".brand_category_mapping (brand, category_index) VALUES
    ('baraka', 'medicine'),
    ('baratto', 'furniture'),
    ('barbie', 'kids'),
    ('barbie', 'apparel'),
    ('barcelona', 'apparel'),
    ('bardahl', 'auto'),
    ('bardahl', 'appliances'),
    ('barer', 'electronics'),
    ('barettoni', 'apparel'),
    ('barhatnyjsezon', 'apparel'),
    ('barkan', 'electronics'),
    ('barmila', 'appliances'),
    ('barneo', 'appliances'),
    ('barokko', 'furniture'),
    ('baron', 'furniture'),
    ('baroque', 'furniture'),
    ('barretoni', 'apparel'),
    ('bars', 'appliances'),
    ('bartek', 'kids'),
    ('bartek', 'apparel'),
    ('bartplast', 'construction'),
    ('barty', 'stationery'),
    ('basaran', 'construction'),
    ('baseus', 'electronics'),
    ('basf', 'construction'),
    ('basharan', 'electronics'),
    ('b.a.shop', 'apparel'),
    ('basic', 'apparel');
[2024-12-05T21:05:41.881+0000] {python.py:240} INFO - Done. Returned value was: INSERT INTO "DDS".brand_category_mapping (brand, category_index) VALUES
    ('baraka', 'medicine'),
    ('baratto', 'furniture'),
    ('barbie', 'kids'),
    ('barbie', 'apparel'),
    ('barcelona', 'apparel'),
    ('bardahl', 'auto'),
    ('bardahl', 'appliances'),
    ('barer', 'electronics'),
    ('barettoni', 'apparel'),
    ('barhatnyjsezon', 'apparel'),
    ('barkan', 'electronics'),
    ('barmila', 'appliances'),
    ('barneo', 'appliances'),
    ('barokko', 'furniture'),
    ('baron', 'furniture'),
    ('baroque', 'furniture'),
    ('barretoni', 'apparel'),
    ('bars', 'appliances'),
    ('bartek', 'kids'),
    ('bartek', 'apparel'),
    ('bartplast', 'construction'),
    ('barty', 'stationery'),
    ('basaran', 'construction'),
    ('baseus', 'electronics'),
    ('basf', 'construction'),
    ('basharan', 'electronics'),
    ('b.a.shop', 'apparel'),
    ('basic', 'apparel');
[2024-12-05T21:05:41.898+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-05T21:05:41.899+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=brand_category_mapping, task_id=extract_sql, run_id=manual__2024-12-05T21:05:16.656190+00:00, execution_date=20241205T210516, start_date=20241205T210541, end_date=20241205T210541
[2024-12-05T21:05:41.924+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2024-12-05T21:05:41.945+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-12-05T21:05:41.948+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
